{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:34:56.983239Z",
     "start_time": "2024-03-18T13:34:56.968207Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from data_setup import CustomDataset\n",
    "from metrics import accuracy_fn, EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Positional_Encoding(torch.nn.Module):\n",
    "    def __init__(self, seq_length, n_dim):\n",
    "        super(Positional_Encoding, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.n_dim = n_dim\n",
    "\n",
    "    def forward(self):\n",
    "        # positional vector\n",
    "        position_encode = torch.zeros((self.seq_length, self.n_dim))\n",
    "        for pos in range(self.seq_length):\n",
    "            for i in range(0, self.n_dim, 2):\n",
    "                position_encode[pos, i] = math.sin(pos / (10000 ** (2 * i / self.n_dim)))\n",
    "                position_encode[pos, i+1] = math.cos(pos / (10000 ** (2 * i / self.n_dim)))\n",
    "        return position_encode\n",
    "\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, n_head, n_dim):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.n_dim = n_dim\n",
    "        self.n_dim_each_head = int(self.n_dim / self.n_head)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # init query, key, value\n",
    "        self.query_matrix = torch.nn.Linear(self.n_dim_each_head, self.n_dim_each_head, bias=False)\n",
    "        self.key_matrix = torch.nn.Linear(self.n_dim_each_head, self.n_dim_each_head, bias=False)\n",
    "        self.value_matrix = torch.nn.Linear(self.n_dim_each_head, self.n_dim_each_head, bias=False)\n",
    "        self.output_matrix = torch.nn.Linear(self.n_dim_each_head * self.n_head, self.n_dim_each_head * self.n_head, bias=False)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):  # (batch_size, seq_length, n_dim)\n",
    "        batch_size = key.size(0)\n",
    "        seq_length = key.size(1)\n",
    "        seq_length_query = query.size(1)\n",
    "        # divide head => (batch_size, seq_length, n_head, n_dim_each_head)\n",
    "        query = query.view(batch_size, seq_length_query, self.n_head, self.n_dim_each_head)\n",
    "        key = key.view(batch_size, seq_length, self.n_head, self.n_dim_each_head)\n",
    "        value = value.view(batch_size, seq_length, self.n_head, self.n_dim_each_head)\n",
    "        q = self.query_matrix(query)\n",
    "        k = self.key_matrix(key)\n",
    "        v = self.value_matrix(value)\n",
    "        # transpose => (batch_size, n_head, seq_length, n_dim_each_head)\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        # -------------------------- Compute MultiHead-Attention --------------------------\n",
    "        \"\"\"\n",
    "        - Step 1: compute matmul(q, k^T)\n",
    "        - Step 2: scale with sqrt(n_dim)\n",
    "        - Step 3: compute softmax => matrix A\n",
    "        - Step 4: compute matmul of matrix A and value matrix\n",
    "        - Step 5: concatenate matrix => matrix Z\n",
    "        - Step 4: compute matmul of matrix Z and matrix W0\n",
    "        \"\"\"\n",
    "        k_T = k.transpose(-1, -2)  # => (batch_size, n_head, n_dim_each_head, seq_length)\n",
    "        product = torch.matmul(q, k_T)  # => (batch_size, n_head, seq_length_query, seq_length)\n",
    "        product = product / math.sqrt(self.n_dim_each_head)\n",
    "        if mask is not None:\n",
    "            product = product.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "        product = product.to(self.device)\n",
    "        scores = F.softmax(product, dim=-1)  # => (batch_size, n_head, seq_length_query, seq_length)\n",
    "        scores = torch.matmul(scores, v)  # => (batch_size, n_head, seq_length_query, n_dim_each_head)\n",
    "        scores = scores.transpose(1, 2)  # => (batch_size, seq_length_query, n_head, n_dim_each_head)\n",
    "        scores = scores.contiguous().view(batch_size, seq_length_query, self.n_dim_each_head * self.n_head)\n",
    "        output = self.output_matrix(scores)\n",
    "        return output\n",
    "\n",
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, n_head, n_dim, n_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        # parameters\n",
    "        self.n_head = n_head\n",
    "        self.n_dim = n_dim\n",
    "        self.n_expansion = n_expansion\n",
    "        # instances\n",
    "        self.multihead = MultiHeadAttention(n_head=self.n_head, n_dim=self.n_dim)\n",
    "        self.norm_attention = torch.nn.LayerNorm(self.n_dim)\n",
    "        self.feedforward = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.n_dim, self.n_expansion * self.n_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(self.n_expansion * self.n_dim, self.n_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        self.norm_feedforward = torch.nn.LayerNorm(self.n_dim)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        multihead_vector = self.multihead(query, key, value)\n",
    "        add_norm_vector = self.norm_attention(multihead_vector + query)\n",
    "        feed_forward_vector = self.feedforward(add_norm_vector)\n",
    "        output = self.norm_feedforward(feed_forward_vector + add_norm_vector)\n",
    "        return output\n",
    "\n",
    "class ViT(torch.nn.Module):\n",
    "    def __init__(self, input_chanel, output_chanel, n_head, n_expansion, n_layer, num_classes):\n",
    "        super(ViT, self).__init__()\n",
    "        # Parameters\n",
    "        self.input_chanel = input_chanel\n",
    "        self.output_chanel = output_chanel\n",
    "        self.n_head = n_head\n",
    "        self.n_expansion = n_expansion\n",
    "        self.n_layer = n_layer\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # Instance\n",
    "        self.patch_embedding = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=self.input_chanel, out_channels=32, kernel_size=(8, 32, 32), stride=(8, 32, 32), padding=(0, 0, 0)),\n",
    "            torch.nn.BatchNorm3d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv3d(in_channels=32, out_channels=self.output_chanel, kernel_size=(1, 7, 7), stride=(1, 7, 7), padding=(0, 0, 0)),\n",
    "            torch.nn.BatchNorm3d(self.output_chanel),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(start_dim=-3)\n",
    "        )\n",
    "        self.transformer_block = TransformerBlock(self.n_head, self.output_chanel, self.n_expansion)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.output_chanel, self.num_classes)\n",
    "        )\n",
    "\n",
    "    def add_cls_token(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        cls_token = torch.nn.Parameter(data=torch.zeros(batch_size, 1, self.output_chanel), requires_grad=True).to(self.device)\n",
    "        return torch.concat([cls_token, x], dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Input shape: (batch_size, chanel, height, width) \"\"\"\n",
    "        x = self.patch_embedding(x)     # => (batch_size, seq_len, output_chanel)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.add_cls_token(x)       # => (batch_size, seq_len+1, output_chanel)\n",
    "        position = Positional_Encoding(seq_length=x.shape[1], n_dim=self.output_chanel)\n",
    "        x = x + position().to(self.device)\n",
    "        for _ in range(self.n_layer):\n",
    "            x = self.transformer_block(x, x, x)\n",
    "            x = self.dropout(x)\n",
    "        x = x[:, 0, :]\n",
    "        output = self.fc(x)\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:34:57.189239Z",
     "start_time": "2024-03-18T13:34:57.172240Z"
    }
   },
   "id": "cfba82e6ed2e50c",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('label.txt', 'r') as f:\n",
    "    classes = [line.rstrip() for line in f.readlines()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:34:57.345242Z",
     "start_time": "2024-03-18T13:34:57.328239Z"
    }
   },
   "id": "e9099046f14f9c90",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\"\"\" Create dataloader \"\"\"\n",
    "root_path = 'processed_data/'\n",
    "train_path = 'train_data.csv'\n",
    "val_path = 'val_data.csv'\n",
    "batch_size = 64\n",
    "train_dataset = CustomDataset(root_path, train_path)\n",
    "val_dataset = CustomDataset(root_path, val_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=True)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_dataset.labels), y=train_dataset.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:34:57.503239Z",
     "start_time": "2024-03-18T13:34:57.490239Z"
    }
   },
   "id": "3235a6e0322b15ca",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" Create Model \"\"\"\n",
    "input_chanel = 3\n",
    "output_chanel = 64\n",
    "n_head = 2\n",
    "n_expansion = 4\n",
    "n_layer = 1\n",
    "num_classes = len(classes)\n",
    "model = ViT(input_chanel, output_chanel, n_head, n_expansion, n_layer, num_classes).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:34:57.725244Z",
     "start_time": "2024-03-18T13:34:57.697239Z"
    }
   },
   "id": "f7ab7397082c212c",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" Create Metrics \"\"\"\n",
    "epochs = 60\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device))\n",
    "early_stopping = EarlyStopping(patience=5, delta=0.01, verbose=True)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "\"\"\" Training model \"\"\"\n",
    "result = {\n",
    "    'train_acc': [],\n",
    "    'train_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_loss': []\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:34:58.011240Z",
     "start_time": "2024-03-18T13:34:57.996240Z"
    }
   },
   "id": "43052ca367782eee",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_recall_precision(y_true, y_pred):\n",
    "    y_pred = torch.argmax(y_pred, dim=-1)\n",
    "    recall = recall_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average='macro', zero_division=0)\n",
    "    precision = precision_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average='macro', zero_division=0)\n",
    "    return recall, precision, f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:34:58.338331Z",
     "start_time": "2024-03-18T13:34:58.326829Z"
    }
   },
   "id": "61dacb4fc30c6b2",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 3.05, Train Acc: 0.12, Train Recall: 0.10, Train Precision: 0.08, Train F1: 0.08, Val Loss: 2.79, Val Acc: 0.39, Val Recall: 0.09, Val Precision: 0.09, Val F1: 0.08 \n",
      "Epoch 2: Train Loss: 2.56, Train Acc: 0.37, Train Recall: 0.33, Train Precision: 0.32, Train F1: 0.29, Val Loss: 2.27, Val Acc: 0.55, Val Recall: 0.13, Val Precision: 0.12, Val F1: 0.11 \n",
      "Epoch 3: Train Loss: 1.84, Train Acc: 0.61, Train Recall: 0.56, Train Precision: 0.57, Train F1: 0.53, Val Loss: 1.73, Val Acc: 0.65, Val Recall: 0.16, Val Precision: 0.17, Val F1: 0.15 \n",
      "Epoch 4: Train Loss: 1.23, Train Acc: 0.79, Train Recall: 0.74, Train Precision: 0.74, Train F1: 0.72, Val Loss: 1.30, Val Acc: 0.76, Val Recall: 0.18, Val Precision: 0.18, Val F1: 0.17 \n",
      "Epoch 5: Train Loss: 0.83, Train Acc: 0.88, Train Recall: 0.85, Train Precision: 0.85, Train F1: 0.84, Val Loss: 1.08, Val Acc: 0.81, Val Recall: 0.20, Val Precision: 0.20, Val F1: 0.19 \n",
      "Epoch 6: Train Loss: 0.59, Train Acc: 0.94, Train Recall: 0.91, Train Precision: 0.91, Train F1: 0.91, Val Loss: 0.92, Val Acc: 0.87, Val Recall: 0.22, Val Precision: 0.21, Val F1: 0.21 \n",
      "Epoch 7: Train Loss: 0.43, Train Acc: 0.96, Train Recall: 0.95, Train Precision: 0.95, Train F1: 0.95, Val Loss: 0.72, Val Acc: 0.89, Val Recall: 0.22, Val Precision: 0.22, Val F1: 0.22 \n",
      "Epoch 8: Train Loss: 0.30, Train Acc: 0.99, Train Recall: 0.98, Train Precision: 0.98, Train F1: 0.98, Val Loss: 0.67, Val Acc: 0.91, Val Recall: 0.22, Val Precision: 0.22, Val F1: 0.22 \n",
      "Epoch 9: Train Loss: 0.22, Train Acc: 0.99, Train Recall: 0.99, Train Precision: 0.99, Train F1: 0.99, Val Loss: 0.63, Val Acc: 0.92, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.22 \n",
      "Epoch 10: Train Loss: 0.18, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.57, Val Acc: 0.92, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 11: Train Loss: 0.14, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.57, Val Acc: 0.92, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 12: Train Loss: 0.11, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.59, Val Acc: 0.92, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 13: Train Loss: 0.09, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.54, Val Acc: 0.93, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 14: Train Loss: 0.07, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.53, Val Acc: 0.93, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 15: Train Loss: 0.06, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.57, Val Acc: 0.93, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 16: Train Loss: 0.05, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.52, Val Acc: 0.94, Val Recall: 0.24, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 17: Train Loss: 0.05, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.52, Val Acc: 0.94, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 18: Train Loss: 0.04, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.52, Val Acc: 0.93, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 19: Train Loss: 0.04, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.53, Val Acc: 0.94, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 20: Train Loss: 0.03, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.49, Val Acc: 0.93, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 21: Train Loss: 0.03, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.50, Val Acc: 0.94, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n",
      "Epoch 22: Train Loss: 0.03, Train Acc: 1.00, Train Recall: 1.00, Train Precision: 1.00, Train F1: 1.00, Val Loss: 0.52, Val Acc: 0.94, Val Recall: 0.23, Val Precision: 0.23, Val F1: 0.23 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m train_acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      5\u001B[0m train_recall, train_precision, train_f1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch, (X, y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m      7\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      8\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mto(device), y\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mD:\\NCKH\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\NCKH\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\NCKH\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\NCKH\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\AI4LIFE\\data_setup.py:24\u001B[0m, in \u001B[0;36mCustomDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# Get video_path\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     tensor_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpaths[index]\n\u001B[1;32m---> 24\u001B[0m     tensor \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;66;03m# Get label\u001B[39;00m\n\u001B[0;32m     26\u001B[0m     output_label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels[index]\n",
      "File \u001B[1;32mD:\\NCKH\\.venv\\lib\\site-packages\\torch\\serialization.py:1026\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1024\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1025\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1026\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile,\n\u001B[0;32m   1027\u001B[0m                      map_location,\n\u001B[0;32m   1028\u001B[0m                      pickle_module,\n\u001B[0;32m   1029\u001B[0m                      overall_storage\u001B[38;5;241m=\u001B[39moverall_storage,\n\u001B[0;32m   1030\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[0;32m   1032\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmmap can only be used with files saved with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1033\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1034\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\NCKH\\.venv\\lib\\site-packages\\torch\\serialization.py:1438\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1436\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1437\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m-> 1438\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1440\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[0;32m   1441\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_metadata(\n\u001B[0;32m   1442\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load.metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialization_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: zip_file\u001B[38;5;241m.\u001B[39mserialization_id()}\n\u001B[0;32m   1443\u001B[0m )\n",
      "File \u001B[1;32mD:\\NCKH\\.venv\\lib\\site-packages\\torch\\_utils.py:203\u001B[0m, in \u001B[0;36m_rebuild_tensor_v2\u001B[1;34m(storage, storage_offset, size, stride, requires_grad, backward_hooks, metadata)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_rebuild_tensor_v2\u001B[39m(\n\u001B[0;32m    201\u001B[0m     storage, storage_offset, size, stride, requires_grad, backward_hooks, metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    202\u001B[0m ):\n\u001B[1;32m--> 203\u001B[0m     tensor \u001B[38;5;241m=\u001B[39m \u001B[43m_rebuild_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    204\u001B[0m     tensor\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m requires_grad\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m metadata:\n",
      "File \u001B[1;32mD:\\NCKH\\.venv\\lib\\site-packages\\torch\\_utils.py:181\u001B[0m, in \u001B[0;36m_rebuild_tensor\u001B[1;34m(storage, storage_offset, size, stride)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_rebuild_tensor\u001B[39m(storage, storage_offset, size, stride):\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;66;03m# first construct a tensor with the correct dtype/device\u001B[39;00m\n\u001B[1;32m--> 181\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_untyped_storage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mset_(storage\u001B[38;5;241m.\u001B[39m_untyped_storage, storage_offset, size, stride)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # ---------------------------------------- Training ----------------------------------------\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_recall, train_precision, train_f1 = 0, 0, 0\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += accuracy_fn(torch.softmax(y_pred, dim=1).argmax(dim=1), y)\n",
    "        recall, precision, f1 = compute_recall_precision(y, y_pred)\n",
    "        train_recall += recall\n",
    "        train_precision += precision\n",
    "        train_f1 += f1\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    train_recall /= len(train_loader)\n",
    "    train_precision /= len(train_loader)\n",
    "    train_f1 /= len(train_loader)\n",
    "    # ---------------------------------------- Validation ----------------------------------------\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    val_recall, val_precision, val_f1 = 0, 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(val_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Forward pass\n",
    "            y_pred = model(X)\n",
    "            # Calculate validation loss and accuracy\n",
    "            val_loss += criterion(y_pred, y).item()\n",
    "            val_acc += accuracy_fn(torch.softmax(y_pred, dim=1).argmax(dim=1), y)\n",
    "            recall, precision, f1 = compute_recall_precision(y, y_pred)\n",
    "            val_recall += recall\n",
    "            val_precision += precision\n",
    "            val_f1 += f1\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc /= len(val_loader)\n",
    "    val_recall /= len(train_loader)\n",
    "    val_precision /= len(train_loader)\n",
    "    val_f1 /= len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.2f}, Train Acc: {train_acc:.2f}, Train Recall: {train_recall:.2f}, Train Precision: {train_precision:.2f}, Train F1: {train_f1:.2f},\"\n",
    "          f\" Val Loss: {val_loss:.2f}, Val Acc: {val_acc:.2f}, Val Recall: {val_recall:.2f}, Val Precision: {val_precision:.2f}, Val F1: {val_f1:.2f} \")\n",
    "    result['train_acc'].append(train_acc)\n",
    "    result['train_loss'].append(train_loss)\n",
    "    result['val_acc'].append(val_acc)\n",
    "    result['val_loss'].append(val_loss)\n",
    "    # ---------------------------------------- Learning rate Schedule ----------------------------------------\n",
    "    lr_scheduler.step(val_loss)\n",
    "    # ---------------------------------------- Check EarlyStopping ----------------------------------------\n",
    "    if early_stopping(val_loss):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:01:07.431396Z",
     "start_time": "2024-03-18T13:34:58.737497Z"
    }
   },
   "id": "fef91b61951f9a76",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(5, 5))\n",
    "plt.plot([i.cpu().detach().numpy() for i in result['train_acc']])\n",
    "plt.plot([i.cpu().detach().numpy() for i in result['val_acc']])\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:01:07.433396Z",
     "start_time": "2024-03-18T14:01:07.432396Z"
    }
   },
   "id": "7989460c58886c93",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(2, figsize=(5, 5))\n",
    "plt.plot(result['train_loss'])\n",
    "plt.plot(result['val_loss'])\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:01:07.434396Z",
     "start_time": "2024-03-18T14:01:07.433396Z"
    }
   },
   "id": "787da60d77466693",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(5, 5))\n",
    "plt.plot([i.cpu().detach().numpy() for i in result['train_acc']])\n",
    "plt.plot([i.cpu().detach().numpy() for i in result['val_acc']])\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:01:07.435396Z",
     "start_time": "2024-03-18T14:01:07.434396Z"
    }
   },
   "id": "47cfe21e6afa4754",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(2, figsize=(5, 5))\n",
    "plt.plot(result['train_loss'])\n",
    "plt.plot(result['val_loss'])\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d140cae0645cda7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class': classes\n",
    "}, 'checkpoint_1.pth.tar')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T13:29:29.982338Z"
    }
   },
   "id": "6c9b722ccae78c52",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T13:29:29.982338Z"
    }
   },
   "id": "23646db6a7fffe24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
